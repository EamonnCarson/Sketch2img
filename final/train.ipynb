{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhCTxBQdmZfN",
        "colab_type": "code",
        "outputId": "01d2eb24-7b1f-4e2c-8e41-c559fcd6e3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnmlRaSl7_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from generator import *\n",
        "from discriminator import *\n",
        "from utils import * \n",
        "from loss import *\n",
        "from dataset import load_sketchygan_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfI0syJonhyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PARAMS\n",
        "\n",
        "# Learning rates for discriminator and generator based on the SketchyGAN paper\n",
        "d_lr = 0.0002\n",
        "g_lr = 0.0001\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwfl1yXjmT8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "photo_sketch_dl = load_sketchygan_dataset(batch_size)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S9rxLpenbzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "netG = Generator(num_classes=125\n",
        "                ).to(device)\n",
        "\n",
        "netD = Discriminator(num_classes=125,\n",
        "                     init_in_channels=6,\n",
        "                     activation=nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
        "                     norm=nn.BatchNorm2d,\n",
        "                     init_out_channels=64,\n",
        "                     image_channels=3,\n",
        "                     init_image_size=64\n",
        "                     ).to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEVZ6WqvqVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizerD = optim.Adam(netD.parameters(), lr=d_lr)\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=g_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acBAuP4_v_b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G_losses = []\n",
        "D_losses = []\n",
        "img_list = []\n",
        "iters = 0\n",
        "acc_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPL7bu3z3Vby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_label = 1.0\n",
        "input_label = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3C0csGOwTlO",
        "colab_type": "code",
        "outputId": "a5d869d8-7eec-4903-8909-872e6bd00ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "print(\"Begin training ...\")\n",
        "begin_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(photo_sketch_dl):\n",
        "        # Assuming data is a list of [photos, labels, sketches]\n",
        "        input_photos, input_sketches, input_labels = data\n",
        "\n",
        "        ## Update netD: maximize log(D(y)) + log(1-D(G(x,z)))\n",
        "        # Train with all-real images\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        dis_label = torch.full((batch_size, 1), real_label, device=device)\n",
        "        aux_label = input_labels #torch.full((batch_size,), input_labels, device=device, dtype=torch.long)\n",
        "        # Forward pass real batch thru D\n",
        "        dis_output_real, aux_output_real = netD(input_photos)\n",
        "        # Calculate loss on all-real batch\n",
        "        dis_errD_real = dis_criterion(dis_output_real, dis_label) #pred_real_natural\n",
        "        aux_errD_real = aux_criterion(aux_output_real, aux_label) #pred_real_class\n",
        "        # Calculate gradients for D in the backward pass\n",
        "        errD_real = dis_errD_real + aux_errD_real\n",
        "        errD_real.backward(retain_graph=True)\n",
        "        D_x = dis_output_real.mean().item()\n",
        "\n",
        "        # compute the current classification accuracy\n",
        "        accuracy = compute_acc(aux_output_real, aux_label)\n",
        "        acc_list.append(accuracy)\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate fake image batch with G \n",
        "        # Generator outputs generated image and noise vector applied on the bottleneck\n",
        "        fake, z = netG(input_labels, input_sketches)\n",
        "        dis_label.data.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        dis_output_fake, aux_output_fake = netD(fake)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        dis_errD_fake = dis_criterion(dis_output_fake, dis_label) #pred_fake_natural\n",
        "        aux_errD_fake = aux_criterion(aux_output_fake, aux_label) #pred_fake_class\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake = dis_errD_fake + aux_errD_fake\n",
        "        errD_fake.backward(retain_graph=True)\n",
        "        D_G_z1 = dis_output_fake.mean().item()\n",
        "        # Calculate DRAGAN Loss\n",
        "        grad_penalty = gradient_penalty(netD, input_photos, fake)\n",
        "        grad_penalty.backward()\n",
        "        # Add the gradients from the all-real and all-fake batches\n",
        "        errD = errD_real + errD_fake + grad_penalty\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ## Update G Network: maximize log(D(G(x,z)))\n",
        "        netG.zero_grad()\n",
        "        dis_label.data.fill_(real_label) #fake labels are real label for generator\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch thru D\n",
        "        dis_output, aux_output = netD(fake)\n",
        "        # Calculate G's loss based on this output\n",
        "        dis_errG = dis_criterion(dis_output, dis_label)\n",
        "        aux_errG = aux_criterion(aux_output, aux_label)\n",
        "        # Calculate gradients for G\n",
        "        errG = dis_errG - aux_errG\n",
        "        errG.backward(retain_graph=True)\n",
        "        # Supervised loss\n",
        "        supervised_loss_G = supervised_loss(fake, input_photos)\n",
        "        # Perceptual loss\n",
        "        perceptual_loss_G = perceptual_loss(fake, input_photos)\n",
        "        # Diversity Loss; Create another fake image\n",
        "        fake_alt , z_alt = netG(input_labels, input_sketches)\n",
        "        diversity_loss_G = diversity_loss(fake, fake_alt, z, z_alt)\n",
        "        errG_spd = supervised_loss_G + perceptual_loss_G[0] + diversity_loss_G\n",
        "        errG_spd.backward()\n",
        "        D_G_z2 = dis_output.mean().item()        \n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Print trainig stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                % (epoch, num_epochs, i, len(photo_sketch_dl),\n",
        "                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
        "                )\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Save a sketch and corresponding photo\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(photo_sketch_dl) - 1)):\n",
        "            img_list.append((fake[0], input_photos[0]))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Begin training ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7b69da53a947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_sketch_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Assuming data is a list of [photos, labels, sketches]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput_photos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sketches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/19Spring/CS182/Final_Project/Sketch2img/final/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0msketch_file_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{row['ImageNetID']}-{row['SketchID']}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msketch_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msketches_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msketch_file_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msketch_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0msketch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msketches_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../learning/datasets/sketchy/256x256/sketch/tx_000000000010/airplane/n02691156_11257-1.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCm15taRy9og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}