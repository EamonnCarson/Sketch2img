{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RhCTxBQdmZfN",
    "outputId": "01d2eb24-7b1f-4e2c-8e41-c559fcd6e3b7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMnmlRaSl7_T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from generator import *\n",
    "from discriminator import *\n",
    "from utils import * \n",
    "from loss import *\n",
    "from dataset import load_sketchygan_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfI0syJonhyi"
   },
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "\n",
    "# Learning rates for discriminator and generator based on the SketchyGAN paper\n",
    "d_lr = 0.0002\n",
    "g_lr = 0.0001\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nwfl1yXjmT8N"
   },
   "outputs": [],
   "source": [
    "photo_sketch_dl = load_sketchygan_dataset(batch_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8S9rxLpenbzV"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "netG = Generator(num_classes=125).to(device)\n",
    "\n",
    "netD = Discriminator(num_classes=125, init_in_channels=3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_criterion = nn.BCEWithLogitsLoss()\n",
    "aux_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blEVZ6WqvqVV"
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=d_lr)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=g_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acBAuP4_v_b4"
   },
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPL7bu3z3Vby"
   },
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "b3C0csGOwTlO",
    "outputId": "a5d869d8-7eec-4903-8909-872e6bd00ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ee26a6ad2934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#         input_photos = input_photos.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         fake = fake.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mgrad_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_photos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mgrad_penalty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Add the gradients from the all-real and all-fake batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/Sketch2img/final/loss.py\u001b[0m in \u001b[0;36mgradient_penalty\u001b[0;34m(discriminator, real_image_sample, fake_image_sample, lambda_, k)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_image_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_image_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_image_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreal_image_sample\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfake_image_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mpred_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Begin training ...\")\n",
    "begin_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(photo_sketch_dl):\n",
    "        # Assuming data is a list of [photos, labels, sketches]\n",
    "        input_photos, input_sketches, input_labels = data\n",
    "        \n",
    "        input_photos = input_photos.to(device)\n",
    "\n",
    "        ## Update netD: maximize log(D(y)) + log(1-D(G(x,z)))\n",
    "        # Train with all-real images\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        dis_label = torch.full((batch_size, 1), real_label, device=device)\n",
    "        aux_label = input_labels #torch.full((batch_size,), input_labels, device=device, dtype=torch.long)\n",
    "        # Forward pass real batch thru D\n",
    "        dis_output_real, aux_output_real = netD(input_photos)\n",
    "        \n",
    "        # Calculate loss on all-real batch\n",
    "        aux_label = aux_label.to(device)\n",
    "        dis_errD_real = dis_criterion(dis_output_real, dis_label) #pred_real_natural\n",
    "        aux_errD_real = aux_criterion(aux_output_real, aux_label) #pred_real_class\n",
    "        # Calculate gradients for D in the backward pass\n",
    "        errD_real = dis_errD_real + aux_errD_real\n",
    "        errD_real.backward(retain_graph=True)\n",
    "        D_x = dis_output_real.mean().item()\n",
    "\n",
    "        # compute the current classification accuracy\n",
    "        accuracy = compute_acc(aux_output_real, aux_label)\n",
    "        acc_list.append(accuracy)\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with G \n",
    "        # Generator outputs generated image and noise vector applied on the bottleneck\n",
    "        input_labels = input_labels.to(device)\n",
    "        input_sketches = input_sketches.to(device)\n",
    "        fake, z = netG(input_labels, input_sketches)\n",
    "        dis_label.data.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        dis_output_fake, aux_output_fake = netD(fake)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        dis_errD_fake = dis_criterion(dis_output_fake, dis_label) #pred_fake_natural\n",
    "        aux_errD_fake = aux_criterion(aux_output_fake, aux_label) #pred_fake_class\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake = dis_errD_fake + aux_errD_fake\n",
    "        errD_fake.backward(retain_graph=True)\n",
    "        D_G_z1 = dis_output_fake.mean().item()\n",
    "        # Calculate DRAGAN Loss\n",
    "#         input_photos = input_photos.to(device)\n",
    "#         fake = fake.to(device)\n",
    "        grad_penalty = gradient_penalty(netD, input_photos, fake, device)\n",
    "        grad_penalty.backward()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake + grad_penalty\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ## Update G Network: maximize log(D(G(x,z)))\n",
    "        netG.zero_grad()\n",
    "        dis_label.data.fill_(real_label) #fake labels are real label for generator\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch thru D\n",
    "        dis_output, aux_output = netD(fake)\n",
    "        # Calculate G's loss based on this output\n",
    "        dis_errG = dis_criterion(dis_output, dis_label)\n",
    "        aux_errG = aux_criterion(aux_output, aux_label)\n",
    "        # Calculate gradients for G\n",
    "        errG = dis_errG - aux_errG\n",
    "        errG.backward(retain_graph=True)\n",
    "        # Supervised loss\n",
    "        supervised_loss_G = supervised_loss(fake, input_photos)\n",
    "        # Perceptual loss\n",
    "        perceptual_loss_G = perceptual_loss(fake, input_photos)\n",
    "        # Diversity Loss; Create another fake image\n",
    "        fake_alt , z_alt = netG(input_labels, input_sketches)\n",
    "        diversity_loss_G = diversity_loss(fake, fake_alt, z, z_alt)\n",
    "        errG_spd = supervised_loss_G + perceptual_loss_G[0] + diversity_loss_G\n",
    "        errG_spd.backward()\n",
    "        D_G_z2 = dis_output.mean().item()        \n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Print trainig stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                % (epoch, num_epochs, i, len(photo_sketch_dl),\n",
    "                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)\n",
    "                )\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Save a sketch and corresponding photo\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(photo_sketch_dl) - 1)):\n",
    "            img_list.append((fake[0], input_photos[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
