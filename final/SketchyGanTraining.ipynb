{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SketchyGanTraining.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"y_yAc6SgdeGJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2ee809e1-37f7-489d-9269-fe1f06b3be79","executionInfo":{"status":"ok","timestamp":1556950640470,"user_tz":420,"elapsed":414,"user":{"displayName":"EAMONN RYU CARSON","photoUrl":"","userId":"14100246608259752130"}}},"source":["GOOGLE_COLAB = True\n","\n","if GOOGLE_COLAB:\n","  # Mount Google Drive\n","  from google.colab import drive\n","  drive.mount('/content/gdrive/')\n","  # Note: you need to put the path to whatever folder you have here\n","  path_prefix = '/content/gdrive/My Drive/CS182_Sketch2Img/Sketch2img/final/'\n","else:\n","  path_prefix = ''"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g_1aLmYYdoKI","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import PIL\n","from timeit import default_timer as timer\n","import sys\n","\n","import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","\n","if GOOGLE_COLAB:\n","  os.chdir(path_prefix) # set working directory to the one inside of My Drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGY9uXXZdw0i","colab_type":"code","colab":{}},"source":["from generator import Generator\n","from discriminator import Discriminator\n","from dataset import load_sketchygan_dataset\n","from loss import discriminator_loss, generator_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbp0MLWFdyCN","colab_type":"code","colab":{}},"source":["# Train parameters: don't change the class size but you can change anything else.\n","batch_size = 10\n","num_classes = 125\n","init_in_channels = 3\n","max_epochs = 10\n","image_save_freq = 500\n","model_save_freq = None # none -> save at end. o.w. -> save every this many iters\n","write_freq = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTM98009eEXR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"475a681a-0b64-4bea-e90b-e650c068e8fd","executionInfo":{"status":"ok","timestamp":1556953344505,"user_tz":420,"elapsed":1516,"user":{"displayName":"EAMONN RYU CARSON","photoUrl":"","userId":"14100246608259752130"}}},"source":["# adapted from https://github.com/jfsantos/dragan-pytorch/blob/master/dragan.py\n","def xavier_init(model):\n","  for param in model.parameters():\n","    if len(param.size()) == 2:\n","      torch.nn.init.xavier_normal(param)\n","\n","ds, dl = load_sketchygan_dataset(8)\n","discriminator = Discriminator(num_classes, init_in_channels)\n","generator = Generator(num_classes)\n","\n","xavier_init(generator)\n","xavier_init(discriminator)\n","\n","opt_g = torch.optim.Adam(generator.parameters())\n","opt_d = torch.optim.Adam(discriminator.parameters())"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  \"\"\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L_WyIxdmpxdc","colab_type":"code","colab":{}},"source":["## NOTE: These two paramaters should be edited so you have reasonable filenames\n","##       When saving, or if you want to load a model that has been saved at\n","##       path_of_run_to_load.\n","run_name = 'test_run'\n","path_of_run_to_load = None\n","\n","models_dir = os.path.join('saved_models', run_name)\n","images_dir = os.path.join('saved_images', run_name)\n","if not os.path.exists(models_dir):\n","  os.makedirs(models_dir)\n","if not os.path.exists(images_dir):\n","  os.makedirs(images_dir)\n","  \n","if path_of_run_to_load:\n","  if os.path.exists(path_of_run_to_load):\n","    checkpoint = torch.load(path_of_run_to_load)\n","    discriminator.load_state_dict(checkpoint['discriminator'])\n","    generator.load_state_dict(checkpoint['generator'])\n","    count = checkpoint['count']\n","    discriminator.eval()\n","    generator.eval()\n","  else:\n","    raise ValueError(\"Path of run to load is invalid.\")\n","else:\n","  count = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCDtteUZplau","colab_type":"code","colab":{}},"source":["for epoch in range(max_epochs):\n","    for batch_idx, (real_images, sketches, class_labels) in enumerate(dl):\n","      # Update discriminator\n","      discriminator.zero_grad()\n","      fake_images, noise = generator.forward(class_labels, sketches).detach()\n","      loss_d = discriminator_loss(discriminator, \n","                                 real_images,\n","                                 fake_images,\n","                                 class_labels)\n","      loss_d.backward()\n","      opt_d.step()\n","      \n","      # Update generator\n","      generator.zero_grad()\n","      loss_g = discriminator_loss(discriminator,\n","                                 generator,\n","                                 real_images,\n","                                 class_labels)\n","      loss_g.backward()\n","      opt_g.step()\n","\n","      # Print out progress periodically\n","      if count % write_freq == 0:\n","        template = 'Epoch [%d/%d] Batch [%d/%d]:\\n\\tDiscriminator Loss = %.4f, \\n\\t Generator Loss = %.4f'\n","        status = template % (epoch, max_epochs, batch_idx, len(dl), loss_d.data[0], loss_g.data[0])\n","        print(status)\n","\n","      # Save real and fake images periodically\n","      if count % image_save_freq == 0:\n","        real_image_path = os.path.join(images_dir, 'real_sample_e%d_b%d.png' % (epoch, batch_idx))\n","        real_image = real_images[0]\n","        real_image = real_image[:, :64, :64]\n","        real_image = real_image.view(1, 3, 64, 64)\n","        torch.utils.save_image(real_image, real_image_path)\n","        \n","        fake_image_path = os.path.join(images_dir, 'fake_sample_e%d_b%d.png' % (epoch, batch_idx))\n","        fake_image = fake_images[0]\n","        fake_image = fake_image[:, :64, :64]\n","        fake_image = fake_image.view(1, 3, 64, 64)\n","        torch.utils.save_image(fake_image, fake_image_path)\n","        \n","      # Save model periodically\n","      if model_save_freq and count % model_save_freq:\n","        model_path = os.path.join(model_dir, '{}_c{}'.format(run_name, count))\n","        torch.save({\n","            'discriminator': discriminator.state_dict(),\n","            'generator': generator.state_dict(),\n","            'count': count,\n","            }, model_path)\n","                            \n","      count += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jchM32UfT7b","colab_type":"code","colab":{}},"source":["# Save model afterwards if you wish by running this cell\n","model_path = os.path.join(model_dir, '{}_final'.format(run_name, count))\n","torch.save({\n","    'discriminator': discriminator.state_dict(),\n","    'generator': generator.state_dict(),\n","    'count': count,\n","    }, model_path)"],"execution_count":0,"outputs":[]}]}